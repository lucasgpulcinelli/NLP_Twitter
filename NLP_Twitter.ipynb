{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "TwitterNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-D_SojO0kwzi",
        "CIDwJKJ9bh8Y",
        "Yux5OJ4gDpsS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit ('venv': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "40e96596fa7b3e3f282e15ffffd5da1c154dcfabfca597f8d4f0be80ba0cb9fb"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# License"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Copyright (C) 2021 Lucas Eduardo Gulka Pulcinelli\n",
        "# This file is licensed under the terms of The 3-Clause BSD License, check the LICENSE file for details"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs and Imports"
      ],
      "metadata": {
        "id": "ZFSTq1EcdXsp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_hub as tfhub\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "ss3MZXLOgV6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d5f35c-9959-4ce5-8eb8-e3bb948b1782"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data extraction"
      ],
      "metadata": {
        "id": "gReygrKUhcJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting all data from csv"
      ],
      "metadata": {
        "id": "cX1LSzdJ1rg5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_all = pd.read_csv(\"./data/NLP_data_raw.csv\")\n",
        "\n",
        "feelings = [\"Optimistic\", \"Thankful\", \"Empathetic\", \"Pessimistic\", \"Anxious\", \"Sad\",\n",
        "            \"Annoyed\", \"Denial\", \"Surprise\", \"Official.report\", \"Joking\"]\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "GZv_mzUUhkri"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_all[feelings] = [[str(i) in label.split() for i in range(len(feelings))] for label in df_all[\"Labels\"]]\n",
        "df_all.head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "AOqAMjYdzanm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "counts = np.zeros(11)\n",
        "for row in df_all[feelings].values:\n",
        "  for i in range(len(row)):\n",
        "    counts[i] += row[i]\n",
        "  \n",
        "plt.barh(feelings, counts)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8r_yv2Wi0-T-",
        "outputId": "b18442bb-5d26-4298-a9c8-3981021b5c43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separating train from validation (not stratified)"
      ],
      "metadata": {
        "id": "Esc9W5Oj4yZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train, val, t_len, v_len = train_test_split(df_all.values, range(len(df_all.values)), test_size=0.2)\n",
        "\n",
        "counts_t = np.zeros(11)\n",
        "for row in [i[3:] for i in train]:\n",
        "  for i in range(len(row)):\n",
        "    counts_t[i] += row[i]\n",
        "\n",
        "counts_v = np.zeros(11)\n",
        "for row in [i[3:] for i in val]:\n",
        "  for i in range(len(row)):\n",
        "    counts_v[i] += row[i]\n",
        "  \n",
        "plt.barh(feelings, counts_t)\n",
        "plt.show()\n",
        "plt.barh(feelings, counts_v)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "KI70F9n942t7",
        "outputId": "a233e1dc-9d83-49a7-fdca-b4fab34039c6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_tweets = np.array([i[1] for i in train])\n",
        "train_labels = np.array([np.array(i[3:]) for i in train]).astype(np.uint8)\n",
        "val_tweets   = np.array([i[1] for i in val])\n",
        "val_labels   = np.array([np.array(i[3:]) for i in val]).astype(np.uint8)"
      ],
      "outputs": [],
      "metadata": {
        "id": "YBgPNdym833r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text preprocessing (tokenization, padding)"
      ],
      "metadata": {
        "id": "DvvVQQQJkN3O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "num_words = 7500 #5000 samples in training/validation data, plus a good amount\n",
        "oov = \"<OOV>\"\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, oov_token=oov)\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(train_tweets)\n",
        "list(tokenizer.word_index)[0:50]"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od6jxhIrkLg1",
        "outputId": "8d258b02-57fa-48b0-a059-88342225b63e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tweet_max_len = 140\n",
        "\n",
        "train_pad = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(train_tweets), maxlen=tweet_max_len)\n",
        "val_pad   = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(val_tweets), maxlen=tweet_max_len)\n",
        "train_pad[0]"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHhC1dptoUd7",
        "outputId": "d821567b-bb18-41bf-9455-465cad16e9fc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Neural Network"
      ],
      "metadata": {
        "id": "X5Je8hmsriXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One feeling, not using LSTM"
      ],
      "metadata": {
        "id": "-D_SojO0kwzi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "embedding_dim = 32\n",
        "model_jok = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(tokenizer.num_words, embedding_dim),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "model_jok.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=\"adam\", \n",
        "                metrics=[\"accuracy\", tfa.metrics.F1Score(num_classes=1, average=\"micro\", threshold=0.4)])\n",
        "model_jok.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "G3gU4JQnpWDx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs = 40\n",
        "\n",
        "\n",
        "model_jok.fit(x=train_pad, y=np.array([i[-1] for i in train_labels]), \n",
        "            validation_data=(val_pad, np.array([i[-1] for i in val])), epochs=epochs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "MSQpEvFyuDoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All feelings, not using LSTM"
      ],
      "metadata": {
        "id": "Y7ibXaSN3rWU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def create_fellings_model(input_dim, num_words, feelings):\n",
        "\n",
        "  fs_outs = []\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=input_dim, name=\"input\")\n",
        "  embed  = tf.keras.layers.Embedding(num_words, 256, name=\"embedding\")(inputs)\n",
        "  pol = tf.keras.layers.GlobalAveragePooling1D(name=\"gpol\")(embed)\n",
        "\n",
        "  for f in feelings:\n",
        "    \n",
        "    f_dense = tf.keras.layers.Dense(32, activation=\"relu\", name=\"dense_\"+f)(pol)\n",
        "    fs_outs.append(tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"out_\"+f)(f_dense))\n",
        "\n",
        "  outputs = tf.keras.layers.concatenate(fs_outs, name=\"output\")\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "      inputs=inputs,\n",
        "      outputs=outputs,\n",
        "      name=\"Twitter_NLP_Simple\"\n",
        "  )\n",
        "\n",
        "  model.compile(loss = tf.keras.losses.mean_squared_error, optimizer = \"adam\",\n",
        "              metrics = [\"accuracy\", tfa.metrics.F1Score(threshold=0.4, num_classes = len(feelings))])\n",
        "  return model\n",
        "\n",
        "model_all = create_fellings_model(tweet_max_len, tokenizer.num_words, feelings)\n",
        "tf.keras.utils.plot_model(model_all)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "NDZI8XqB3uFp",
        "outputId": "14106ddd-bc50-46db-e49e-a97e9a8bef40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs = 30\n",
        "\n",
        "\n",
        "model_all.fit(x=train_pad, y=train_labels, validation_data=(val_pad, val_labels), epochs=epochs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "r0vxTkI_AAxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One feeling, with bidirectional LSTM"
      ],
      "metadata": {
        "id": "CIDwJKJ9bh8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "embedding_dim = 32\n",
        "model_jok = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(tokenizer.num_words, embedding_dim),\n",
        "    tf.keras.layers.Dropout(0.7),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dropout(0.7),\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.7),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "\n",
        "model_jok.compile(loss=tf.keras.losses.mean_squared_error, optimizer=\"adam\", \n",
        "                metrics=[\"accuracy\", tfa.metrics.F1Score(num_classes=1, threshold=0.3)])\n",
        "model_jok.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "7bK-mtBNbmtf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs = 20\n",
        "\n",
        "\n",
        "model_jok.fit(x=train_pad, y=np.array([i[-1] for i in train_labels]), validation_data=(val_pad, np.array([i[-1] for i in val])), epochs=epochs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7JGLYGYZcSQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All feelings, bidirectional LSTM"
      ],
      "metadata": {
        "id": "Yux5OJ4gDpsS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def create_fellings_model(input_dim, num_words, feelings):\n",
        "\n",
        "  fs_outs = []\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=input_dim, name=\"input\")\n",
        "  embed  = tf.keras.layers.Embedding(num_words, 128, name=\"embed\")(inputs)\n",
        "  lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True), name=\"lstm1\")(embed)\n",
        "  lstm2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64), name=\"lstm2\")(lstm1)\n",
        "\n",
        "  for f in feelings:\n",
        "    f_dense = tf.keras.layers.Dense(32, activation=\"relu\", name=\"dense_\"+f, kernel_initializer = \"he_uniform\")(lstm2)\n",
        "    fs_outs.append(tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"out_\"+f, )(f_dense))\n",
        "\n",
        "  outputs = tf.keras.layers.concatenate(fs_outs, name=\"output\")\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "      inputs=inputs,\n",
        "      outputs=outputs,\n",
        "      name=\"Twitter_NLP_LSTM\"\n",
        "  )\n",
        "\n",
        "  model.compile(loss = tf.keras.losses.mean_squared_error, \n",
        "              optimizer = \"adam\",\n",
        "              metrics = [\"accuracy\", tfa.metrics.F1Score(average=\"macro\", threshold=0.4, num_classes = len(feelings))])\n",
        "  return model\n",
        "\n",
        "model_all = create_fellings_model(tweet_max_len, tokenizer.num_words, feelings)\n",
        "tf.keras.utils.plot_model(model_all)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "nhiTxLB0Dy_Z",
        "outputId": "121e8f48-01e4-4c5a-b5b3-fa49d366db7a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs = 10\n",
        "\n",
        "\n",
        "model_all.fit(x=train_pad, y=train_labels, validation_data=(val_pad, val_labels), epochs=epochs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "sJ9bsHAoD3CZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "34d37f8f-c59b-4756-b43d-bc9309f47fea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained Transformer"
      ],
      "metadata": {
        "id": "eN94YVQ7dE77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "  PREPROCESS_MODEL = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "  BERT_MODEL       = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "  prep_l = tfhub.KerasLayer(PREPROCESS_MODEL, name=\"preprocess\")\n",
        "  bert_l = tfhub.KerasLayer(BERT_MODEL, name=\"bert\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "REEKIgBbmkN2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def create_fellings_model(feelings):\n",
        "\n",
        "  fs_outs = {}\n",
        "  text = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
        "  prep = prep_l(text)\n",
        "  bert = bert_l(prep)\n",
        "  lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, name=\"lstm1\"))(bert[\"sequence_output\"])\n",
        "  lstm2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, name=\"lstm2\"))(lstm1)\n",
        "\n",
        "  for f in feelings:\n",
        "    f_dense = tf.keras.layers.Dense(32, activation=\"relu\", name=\"dense_\"+f)(lstm2)\n",
        "    fs_outs[f]   = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"out_\"+f)(f_dense)\n",
        "\n",
        "  outputs = tf.keras.layers.concatenate(fs_outs.values(), name=\"output\")\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "      inputs=text,\n",
        "      outputs=outputs,\n",
        "      name=\"Twitter_NLP_BERT\"\n",
        "  )\n",
        "\n",
        "  model.compile(loss = tf.keras.losses.categorical_crossentropy, optimizer = \"adam\",\n",
        "              metrics = [tfa.metrics.F1Score(average=\"macro\", threshold=0.3, num_classes=len(feelings))])\n",
        "  return model\n",
        "\n",
        "model_all = create_fellings_model(feelings)\n",
        "tf.keras.utils.plot_model(model_all)"
      ],
      "outputs": [],
      "metadata": {
        "id": "UqYJyyQIdNGT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "8d9965be-9102-4744-c365-f128bc78f4f5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs = 10\n",
        "\n",
        "model_all.fit(x=train_tweets, y=train_labels, validation_data=(val_tweets, val_labels), epochs=epochs)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "xeGdmo7iHsv7",
        "outputId": "4aa934ab-62fd-4ed6-b1ff-e4b4bb4d77fc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making predictions"
      ],
      "metadata": {
        "id": "CEJaBL8pRQk1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred = model_all(val_pad[:30])\n",
        "\n",
        "for i in range(30):\n",
        "  for j in range(len(feelings)):\n",
        "    if pred[i][j] > 0.3:\n",
        "      print(feelings[j], end=' ')\n",
        "  print()\n",
        "  for j in range(len(feelings)):\n",
        "    if val_labels[i][j]:\n",
        "      print(feelings[j], end=' ')\n",
        "  print()\n",
        "  print()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm9KSqIyMeTK",
        "outputId": "4063d878-6ebd-4cd0-ad6b-0a92e81c899e"
      }
    }
  ]
}